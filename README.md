# FaceWise Video Toolkit

A comprehensive Python toolkit for face detection, tracking, and video processing with advanced portrait cropping capabilities. Built on YOLOv5Face for robust face detection and OpenCV for video processing.

## Features

### ðŸŽ¯ Face Detection & Tracking
- **YOLOv5Face Integration**: High-performance face detection using YOLOv5Face models
- **Multi-face Tracking**: Track multiple faces across video frames using CSRT or KCF trackers
- **Adaptive Detection**: Intelligent detection scheduling with fallback mechanisms
- **Mouth Tracking**: Specialized mouth region tracking with landmark-based bounding boxes

### ðŸ“¹ Video Processing Pipelines
- **Shot Feature Extraction**: Automatic scene detection and face analysis per shot
- **Frame-by-Frame Processing**: Real-time face tracking with visual feedback
- **JSON Output**: Structured data export for face coordinates and tracking metadata

### âœ‚ï¸ Portrait Video Cropping
- **Smart Cropping**: Automatic portrait-mode cropping based on face positions
- **Multi-face Support**: Handles 1-3 faces with different cropping strategies:
  - Single face: Centered portrait crop
  - Two faces: Upright or angular crop with rotation/scaling
  - Three faces: Optimized vertical alignment
- **Aspect Ratio Control**: Configurable output dimensions (default: 720x1560, 2.17:1)
- **Audio Preservation**: Automatic audio track restoration using FFmpeg

### ðŸ”§ Post-processing Tools
- **JSON Validation**: Schema-based validation for shot features output
- **Audio Tools**: FFmpeg integration for audio track management
- **Crop Helpers**: Advanced geometric transformations for face alignment

## Installation

### Prerequisites
- Python 3.10+ (tested with Python 3.13)
- FFmpeg (for audio processing)

### Setup Virtual Environment (Recommended)
```bash
# Create virtual environment
python3 -m venv venv

# Activate virtual environment
source venv/bin/activate  # On macOS/Linux
# or
venv\Scripts\activate     # On Windows
```

### Install Dependencies

#### Runtime Dependencies
```bash
pip install -r requirements.txt
```

#### Development and Testing
```bash
pip install -r requirements-dev.txt
```

### Verify Installation
```bash
# Test imports
python -c "import facekit; print('âœ… FaceKit installed successfully')"

# Run test suite
pytest tests/ -v

# Test CLI tools
python -m facekit.cli.shot_features_cli --help
```

## Quick Start

### 0. Verify Installation
First, ensure everything is working correctly:
```bash
# Activate virtual environment
source venv/bin/activate

# Test the installation
python -c "import facekit; print('âœ… FaceKit ready!')"

# Run tests (optional but recommended)
pytest tests/ -v
```

### 1. Extract Shot Features
Analyze a video to detect scenes and extract face information per shot:

```bash
python -m facekit.cli.shot_features_cli input_video.mp4 --output video_shots.json
```

### 2. Face Tracking with Visual Output
Process a video with real-time face tracking visualization:

```python
from facekit.pipeline.mouthtrack_frame_by_frame import multiface_mouthtrack

multiface_mouthtrack(
    input_path="input_video.mp4",
    output_path="tracked_output.mp4",
    model_path="models/yolov5n_state_dict.pt",
    config_path="models/yolov5n.yaml",
    show_periodic=True
)
```

### 3. Generate Tracking JSON
Export face tracking data to JSON format:

```python
from facekit.pipeline.json_writer import multiface_tracking_to_json

multiface_tracking_to_json(
    input_path="input_video.mp4",
    output_json_path="tracking_data.json",
    model_path="models/yolov5n_state_dict.pt",
    config_path="models/yolov5n.yaml"
)
```

### 4. Portrait Video Cropping
Create portrait-mode videos from tracking data:

```python
from facekit.postprocessing.crop_portrait_video import crop_video_from_json

crop_video_from_json(
    json_path="tracking_data.json",
    video_path="input_video.mp4",
    output_path="portrait_output.mp4",
    aspect_ratio=2.17,
    output_size=(720, 1560)
)
```

## Project Structure

```
facekit/
â”œâ”€â”€ cli/                    # Command-line interfaces
â”‚   â”œâ”€â”€ shot_features_cli.py
â”‚   â””â”€â”€ visualize_shots_cli.py
â”œâ”€â”€ detection/              # Face detection core
â”‚   â”œâ”€â”€ detection_helpers.py
â”‚   â”œâ”€â”€ tracker_base.py
â”‚   â””â”€â”€ yolo5face_model.py
â”œâ”€â”€ pipeline/               # Processing pipelines
â”‚   â”œâ”€â”€ generate_shot_features.py
â”‚   â”œâ”€â”€ json_writer.py
â”‚   â””â”€â”€ mouthtrack_frame_by_frame.py
â”œâ”€â”€ postprocessing/         # Video post-processing
â”‚   â”œâ”€â”€ crop_helpers.py
â”‚   â”œâ”€â”€ crop_portrait_video.py
â”‚   â””â”€â”€ validate_shot_features_json.py
â”œâ”€â”€ tracking/               # Face and mouth tracking
â”‚   â”œâ”€â”€ face_tracker.py
â”‚   â””â”€â”€ mouth_tracker.py
â”œâ”€â”€ output/                 # Output utilities
â”‚   â”œâ”€â”€ audio_tools.py
â”‚   â””â”€â”€ json_writer.py
â”œâ”€â”€ utils/                  # Utility functions
â”‚   â””â”€â”€ geometry.py
â””â”€â”€ yolov5faceInference/    # YOLOv5Face wrapper
```

## Configuration

### Model Files
The toolkit includes pre-trained YOLOv5Face models:
- **YOLOv5 Weights**: `models/yolov5n_state_dict.pt` (included)
- **Model Config**: `models/yolov5n.yaml` (included)
- **Alternative Model**: `facekit/yolov5faceInference/yolo5face/yolov5s-face.pt` (larger model)

> **Note**: The default models are included in the repository. For custom models, update the paths in your function calls.

### Key Parameters
- `min_face`: Minimum face size in pixels (default: 10)
- `track_interval`: Frames between detections (default: 30)
- `tracker_type`: "CSRT" or "KCF" (default: "CSRT")
- `target_size`: Detection input size (default: 640)

## Output Formats

### Shot Features JSON
Structured output with scene detection and face analysis:
```json
{
  "shots": [
    {
      "shot_number": 1,
      "first_frame": 0,
      "last_frame": 299,
      "detected_faces": {
        "face_count": 2,
        "face_details": [
          {
            "center_x": 45.5,
            "center_y": 32.1,
            "face_width": 15.2,
            "face_height": 20.8
          }
        ]
      },
      "detected_graphics": {}
    }
  ]
}
```

### Tracking JSON
Frame-by-frame face tracking data:
```json
[
  {
    "frame": 0,
    "faces": [
      {
        "x": 100,
        "y": 150,
        "w": 80,
        "h": 100,
        "conf": 0.95,
        "source": "detected"
      }
    ]
  }
]
```

## Testing

Run the test suite:
```bash
pytest
```

Test coverage includes:
- Face detection and tracking algorithms
- Video processing pipelines
- Portrait cropping functionality
- JSON validation and output formats
- Audio processing tools

## Requirements

### Core Dependencies
- Python 3.10+ (tested with Python 3.13)
- PyTorch 2.7.1+
- torchvision 0.22.1+
- OpenCV (opencv-python, opencv-contrib-python)
- NumPy 2.3.0+
- PyYAML 6.0.2+
- Pillow 11.2.1+
- JSONSchema 4.24.0+
- PySceneDetect 0.6.6+

### System Dependencies
- FFmpeg (for audio processing)

### Development Dependencies
- pytest 8.4.1+
- All runtime dependencies

## Development & Testing

### Running Tests
The project includes comprehensive test coverage (32 tests):

```bash
# Run all tests
pytest tests/ -v

# Run specific test modules
pytest tests/test_detection_helpers.py -v
pytest tests/test_pipeline_shot_features.py -v
pytest tests/test_postprocessing_crop.py -v
```

### Test Coverage
- âœ… Face detection and tracking algorithms
- âœ… Video processing pipelines
- âœ… Portrait cropping functionality (1-3 faces)
- âœ… JSON validation and output formats
- âœ… Audio processing tools
- âœ… YOLOv5Face model integration
- âœ… Mouth tracking and landmark detection

### Recent Fixes (v2024.1)
- ðŸ”§ Fixed module import structure with proper `__init__.py` files
- ðŸ”§ Added missing dependencies (PyYAML, torchvision, pillow)
- ðŸ”§ Resolved YOLOv5Face integration issues
- ðŸ”§ Updated requirements.txt with complete dependency list
- âœ… All 32 tests now passing

## Troubleshooting

### Common Issues

#### Import Errors
If you encounter module import errors:
```bash
# Ensure you're in the virtual environment
source venv/bin/activate

# Reinstall dependencies
pip install -r requirements.txt

# Verify installation
python -c "import facekit; print('Success')"
```

#### Missing Dependencies
If you get `ModuleNotFoundError`:
```bash
# Install missing packages individually
pip install PyYAML torchvision pillow

# Or reinstall all requirements
pip install -r requirements.txt --force-reinstall
```

#### CUDA/GPU Issues
For GPU acceleration:
```bash
# Check CUDA availability
python -c "import torch; print(f'CUDA available: {torch.cuda.is_available()}')"

# Install CUDA-compatible PyTorch if needed
pip install torch torchvision --index-url https://download.pytorch.org/whl/cu118
```

#### FFmpeg Not Found
For audio processing features:
```bash
# macOS
brew install ffmpeg

# Ubuntu/Debian
sudo apt update && sudo apt install ffmpeg

# Windows
# Download from https://ffmpeg.org/download.html
```

## License

This project incorporates the YOLOv5Face model wrapper, which is released under the MIT License.
